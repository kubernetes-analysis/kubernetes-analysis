#!/usr/bin/env python3
import argparse
import datetime
import json
import os
import time
from typing import Any, Optional, Tuple

from github import Github, Repository
from loguru import logger

from src.data import Data

GITHUB_TOKEN = "GITHUB_TOKEN"
API_UPDATE_FILE = ".update"


def main():
    args = parse_args()

    if args.update_api:
        logger.info("Retrieving issues and PRs")
        token = get_github_token()
        github = Github(token)
        repo = github.get_repo("kubernetes/kubernetes")

        logger.info("Updating API")
        update_api(repo)

    elif args.update_data:
        logger.info("Updating local data")
        Data(parse=True).dump()

    else:
        logger.info("Dumping all issues")
        dump_api(repo)


def parse_args() -> Any:
    parser = argparse.ArgumentParser()
    update_group = parser.add_mutually_exclusive_group()
    update_group.add_argument("--update-api",
                              "-u",
                              action="store_true",
                              help="Update the API json")
    update_group.add_argument("--update-data",
                              "-d",
                              action="store_true",
                              help="Update the data set")
    return parser.parse_args()


def get_github_token() -> Optional[str]:
    logger.info("Getting {} from environment variable", GITHUB_TOKEN)
    token = os.environ.get(GITHUB_TOKEN)
    if token is None:
        logger.critical("{} environment variable not set", GITHUB_TOKEN)
    return token


def dump_api(repo: Repository):
    result = []

    # We use the first (latest) issue as indicator of how many data we have to
    # fetch
    issues = repo.get_issues(state="all")
    latest_issue = issues[0]
    count = latest_issue.number
    logger.info("Pulling {} items", count)

    for i in range(1, count + 1):
        try:
            issue = repo.get_issue(i)
            logger.info("{}: {}", issue.number, issue.title)
            result.append(issue.raw_data)
        except Exception as err:
            logger.info("Unable to get data, waiting a minute: {}", err)
            time.sleep(60)

    with open(Data.API_DATA_JSON, "w") as data_file:
        json.dump(result, data_file)

    logger.info("Done exporting {} items", i)
    Data.api_to_tarball()


def update_api(repo: Repository):
    (update_file, date) = get_update_file_date(API_UPDATE_FILE)

    json_list = []
    for issue in repo.get_issues(
            since=date,
            sort="updated",
            state="all",
    ):
        logger.info("{}: {}", issue.number, issue.title)
        json_list.append(issue.raw_data)

    data = Data()

    logger.info("Updating data")
    data.update_api_data(json_list)

    logger.info("Saving data")
    data.dump_api()

    Data.api_to_tarball()
    write_update_file_date(update_file)


def get_update_file_date(file_name: str) -> Tuple[Any, Any]:
    # load the update file contents
    update_file = open(file_name, "r+")
    date = datetime.datetime.strptime(update_file.read().strip(),
                                      "%Y-%m-%dT%H:%M:%S.%f")
    logger.info("Got update timestamp: {}", date.isoformat())
    return (update_file, date)


def write_update_file_date(update_file: Any):
    # update the file
    update_file.seek(0, 0)
    new_date = datetime.datetime.utcnow().isoformat()
    logger.info("New update timestamp: {}", new_date)
    update_file.write(new_date)


if __name__ == "__main__":
    main()
